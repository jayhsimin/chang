{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "298fff38-4f4a-46d9-89cd-31fa5597caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c177d2e1-be6a-42ab-954c-40b120d9fff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FAG&THICKNESS合併\n",
    "\n",
    "pp=r'C:\\Users\\vghuser\\Desktop\\xxx\\all_s'\n",
    "tt=r'C:\\Users\\vghuser\\Desktop\\TT\\all_s'\n",
    "\n",
    "cpath=os.path.join(pp,'all_c')\n",
    "if not os.path.isdir(cpath):\n",
    "    os.mkdir(cpath)\n",
    "\n",
    "# print(path)\n",
    "files = glob(f'{pp}\\*.csv')    \n",
    "file1s = glob(f'{tt}\\*.csv') \n",
    "\n",
    "oo=[]\n",
    "for filess in file1s:\n",
    "    basenames = os.path.basename(filess)\n",
    "    bb = os.path.splitext(basenames)[0]   \n",
    "    # print(filess)\n",
    "    oo.append(filess)\n",
    "\n",
    "for file in files:\n",
    "    df_list=pd.read_csv(file)\n",
    "    basenames = os.path.basename(file)\n",
    "    bk = os.path.splitext(basenames)[0]\n",
    "    BB=bk.split('_')[1]\n",
    "    CC=bk.split('_')[2]\n",
    "    DD=BB+\"_\"+CC\n",
    "\n",
    "    \n",
    "    if DD =='12r_s':\n",
    "        df = pd.merge(df_list, pd.read_csv(oo[0]), on='id1')\n",
    "    if DD =='12s_s':\n",
    "        df = pd.merge(df_list, pd.read_csv(oo[1]), on='id1')        \n",
    "    if DD =='4r_s':\n",
    "        df = pd.merge(df_list, pd.read_csv(oo[2]), on='id1')\n",
    "    if DD =='4s_s':\n",
    "        df = pd.merge(df_list, pd.read_csv(oo[3]), on='id1')\n",
    "    if DD =='8r_s':\n",
    "        df = pd.merge(df_list, pd.read_csv(oo[4]), on='id1')\n",
    "    if DD =='8s_s':\n",
    "        df = pd.merge(df_list, pd.read_csv(oo[5]), on='id1')\n",
    "        \n",
    "    # for i in range(1,a+1):\n",
    "    # df[f'W{i}'] = df[f'W{i}'] - df[f'BINW{i}']\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.to_csv(f'{cpath}\\{bk}.csv',columns=['id1','xai_rank','t_rank'],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45e9fc9-ad30-414d-a7ed-1ff8c6cf05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=input('請輸入欲合併最外檔案路徑')\n",
    "tt=input('請輸入thickness 整個file檔路徑')\n",
    "\n",
    "# df['A'] = np.nan\n",
    "# df['B'] = np.nan\n",
    "cpath=os.path.join(pp,'all_c')\n",
    "if not os.path.isdir(cpath):\n",
    "    os.mkdir(cpath)\n",
    "path=os.path.join(pp,'all_s')\n",
    "path1=os.path.join(tt,'all_s')\n",
    "# print(path)\n",
    "files = glob(f'{path}\\*.csv')    \n",
    "file1s = glob(f'{path1}\\*.csv') \n",
    "\n",
    "oo=[]\n",
    "for filess in file1s:\n",
    "    basenames = os.path.basename(filess)\n",
    "    bb = os.path.splitext(basenames)[0]   \n",
    "    # print(filess)\n",
    "    oo.append(filess)\n",
    "\n",
    "for file in files:\n",
    "    df_list=pd.read_csv(file)\n",
    "    basenames = os.path.basename(file)\n",
    "    bk = os.path.splitext(basenames)[0]\n",
    "    BB=bk.split('_')[1]\n",
    "    CC=bk.split('_')[2]\n",
    "    DD=BB+\"_\"+CC\n",
    "    print(bk)\n",
    "    \n",
    "    if DD =='12r_s':\n",
    "        df = pd.merge(df_list, pd.read_csv(oo[0]), on='id1')\n",
    "    if DD =='12s_s':\n",
    "        df = pd.merge(df_list, pd.read_csv(oo[1]), on='id1')        \n",
    "    if DD =='4r_s':\n",
    "        df = pd.merge(df_list, pd.read_csv(oo[2]), on='id1')\n",
    "    if DD =='4s_s':\n",
    "        df = pd.merge(df_list, pd.read_csv(oo[3]), on='id1')\n",
    "    if DD =='8r_s':\n",
    "        df = pd.merge(df_list, pd.read_csv(oo[4]), on='id1')\n",
    "    if DD =='8s_s':\n",
    "        df = pd.merge(df_list, pd.read_csv(oo[5]), on='id1')\n",
    "        \n",
    "    # for i in range(1,a+1):\n",
    "    # df[f'W{i}'] = df[f'W{i}'] - df[f'BINW{i}']\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.to_csv(f'{cpath}\\{bk}_c.csv',columns=['id1','xai_rank','f_rank'],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ef2fb497-0e5d-4525-b28f-cf45074e44a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'read_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [272]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_c.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m],index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m BB \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8s\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;129;01mand\u001b[39;00m bb \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8s\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 70\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m(filess),pd\u001b[38;5;241m.\u001b[39mread_csv(file) , on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     71\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXW\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBINW\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     72\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_c.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m],index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'read_csv'"
     ]
    }
   ],
   "source": [
    "# pp=input('請輸入欲合併最外檔案路徑')\n",
    "# tt=input('請輸入thickness 整個file檔路徑')\n",
    "# a=int(input('幾切'))\n",
    "p=r'C:\\Users\\vghuser\\Desktop\\bb\\xai'\n",
    "t=r'C:\\Users\\vghuser\\Desktop\\bb\\bin'\n",
    "oo=[]\n",
    "nn=[]\n",
    "lis=['a','b','c','d']\n",
    "for i in range(1,5):\n",
    "    for li in lis:\n",
    "        pp=os.path.join(p,li)\n",
    "        tt=os.path.join(t,li)\n",
    "\n",
    "\n",
    "        # df['A'] = np.nan\n",
    "        # df['B'] = np.nan\n",
    "        cpath=os.path.join(r'C:\\Users\\vghuser\\Desktop\\bb','all_c')\n",
    "        if not os.path.isdir(cpath):\n",
    "            os.mkdir(cpath)\n",
    "        # path=os.path.join(pp,'all_s')\n",
    "        # path1=os.path.join(tt,'all_s')\n",
    "        # print(path)\n",
    "        files = glob(f'{pp}\\*.csv')    \n",
    "        file1s = glob(f'{tt}\\*.csv') \n",
    "\n",
    "        for filess in file1s:  \n",
    "            basenames = os.path.basename(filess)\n",
    "            bs = os.path.splitext(basenames)[0]\n",
    "            aa=bs.split('_')[0]\n",
    "            bb=bs.split('_')[1]\n",
    "            # oo.append(filess)\n",
    "            # print(filess)\n",
    "            # p1=pd.read_csv(filess)\n",
    "            # print(basenames)\n",
    "\n",
    "\n",
    "            # cc=bs.split('_')[2]\n",
    "            # print(bb)\n",
    "\n",
    "        for file in files:\n",
    "            # df_list=pd.read_csv(file)\n",
    "            basenames = os.path.basename(file)\n",
    "            bk = os.path.splitext(basenames)[0]\n",
    "            BB=bk.split('_')[1]\n",
    "            nn.append(filess)\n",
    "            # print(file)\n",
    "            # CC=bk.split('_')[2]\n",
    "            # DD=BB+\"_\"+CC\n",
    "            \n",
    "            \n",
    "#             # p2=pd.read_csv(file)\n",
    "# print(oo[0],nn[0])\n",
    "\n",
    "        if BB =='12r'and bb == '12r':\n",
    "            df = pd.merge(pd.read_csv(filess),pd.read_csv(file) , on='id1')\n",
    "        if BB =='12s'and bb == '12s':\n",
    "            df = pd.merge(pd.read_csv(filess),pd.read_csv(file), on='id1')        \n",
    "        if BB =='4r'and bb == '4r':\n",
    "            df = pd.merge(pd.read_csv(filess),pd.read_csv(file), on='id1')\n",
    "            df[f'W{i}'] = df[f'XW{i}'] - df[f'BINW{i}']\n",
    "            df.to_csv(f'{cpath}\\{bk}_c.csv',columns=['id1',f'W{i}'],index=False)\n",
    "        print(f'{cpath}\\{bk}_c.csv')\n",
    "        if BB =='4s'and bb == '4s':\n",
    "            df = pd.merge(pd.read_csv(filess),pd.read_csv(file), on='id1')\n",
    "        if BB =='8r'and bb == '8r':\n",
    "            df = pd.merge(pd.read_csv(filess),pd.read_csv(file) , on='id1')\n",
    "            df[f'W{i}'] = df[f'XW{i}'] - df[f'BINW{i}']\n",
    "            df.to_csv(f'{cpath}\\{bk}_c.csv',columns=['id1',f'W{i}'],index=False)\n",
    "        if BB =='8s'and bb == '8s':\n",
    "            df = pd.merge(pd.read_csv(filess),pd.read_csv(file) , on='id1')\n",
    "            df[f'W{i}'] = df[f'XW{i}'] - df[f'BINW{i}']\n",
    "            df.to_csv(f'{cpath}\\{bk}_c.csv',columns=['id1',f'W{i}'],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f1a64-23bf-4211-8e05-17de9771ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(f'{filepath}\\*.csv')    \n",
    "\n",
    "df_list = [pd.read_csv(file) for file in files]  #串列中包含兩個Pandas DataFrame\n",
    "\n",
    "df = pd.merge(df_list[0], df_list[1], on='id1')\n",
    "df\n",
    "for i in range(1,a+1):\n",
    "    df[f'W{i}'] = df[f'W{i}'] - df[f'BINW{i}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1f1d8de3-e653-4d89-b625-9e43965e98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(a, b):\n",
    "    a = set(a)\n",
    "    b = set(b)\n",
    "\n",
    "    intersection = len(a.intersection(b))\n",
    "    union = len(a.union(b))\n",
    "\n",
    "    return intersection / union\n",
    "def build_kmers(sequence, ksize):\n",
    "    kmers = []\n",
    "    n_kmers = len(sequence) - ksize + 1\n",
    "\n",
    "    for i in range(n_kmers):\n",
    "        kmer = sequence[i:i + ksize]\n",
    "        kmers.append(kmer)\n",
    "    return kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3a3f44d3-1cdb-4a56-9b18-4deee94c638f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.1, 0.05263157894736842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\vghuser\\Desktop\\6\\x1234_12r_k.csv')\n",
    "CK=[]\n",
    "DK=[]\n",
    "ss=[]\n",
    "tt=[]\n",
    "for i in range(df.shape[0]):\n",
    "    # print(i)\n",
    "    \n",
    "    CC=re.findall(r\"\\d+\",df['x12_rank'][i])\n",
    "    DD=re.findall(r'\\d+',df['x34_rank'][i])\n",
    "    CK.append(CC)\n",
    "    DK.append(DD)    \n",
    "df['xai_rlist']=CK\n",
    "df['t_rlist']=DK\n",
    "\n",
    "for s in df['xai_rlist']:\n",
    "    # apa=int(i)\n",
    "    # print(apa)\n",
    "    results = list(map(int, s))\n",
    "    ss.append(results)\n",
    "for t in df['t_rlist']:\n",
    "    # apa=int(i)\n",
    "    # print(apa)\n",
    "    results = list(map(int, t))\n",
    "    tt.append(results)\n",
    "df['AAA']=ss\n",
    "df['BBB']=tt\n",
    "GG=tuple(ss[20])\n",
    "G1=tuple(tt[20])\n",
    "\n",
    "# P = np.array(GG)\n",
    "# Q = np.array(G1)\n",
    "\n",
    "\n",
    "# dists=[i for i in range(len(P))]\n",
    "# Wasserstein_Distance=scipy.stats.wasserstein_distance(dists,dists,P,Q)\n",
    "# print(Wasserstein_Distance)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Approximate_string_distance\n",
    "# Approximate_string_distance = fuzz.ratio(GG,G1)\n",
    "# print(Approximate_string_distance)\n",
    "# partial_ratio = fuzz.partial_ratio(GG,G1)\n",
    "# print(partial_ratio)\n",
    "\n",
    "# #LA\n",
    "# ratio = Levenshtein.ratio(GG, G1)\n",
    "# dist = Levenshtein.distance(GG, G1)\n",
    "# print('ratio={0}, dist={1}'.format(ratio, dist))\n",
    "\n",
    "\n",
    "# #hamming_distance\n",
    "# hamming_distance = hamming(GG, G1)*len(GG)\n",
    "# print(hamming_distance)\n",
    "\n",
    "\n",
    "#KMER\n",
    "CC=[]\n",
    "\n",
    "for K in range(1,10):\n",
    "\n",
    "    kmers1 = build_kmers(GG, K)\n",
    "    kmers2 = build_kmers(G1, K)\n",
    "\n",
    "    if K==1:\n",
    "        kmer1=jaccard_similarity(kmers1, kmers2)\n",
    "        CC.append(kmer1)\n",
    "\n",
    "        # print(kmer1,K)\n",
    "    elif K==2:\n",
    "        kmer2=jaccard_similarity(kmers1, kmers2)\n",
    "        CC.append(kmer2)\n",
    "        # print(kmer2,K)\n",
    "    elif K==3:\n",
    "        kmer3=jaccard_similarity(kmers1, kmers2)\n",
    "        CC.append(kmer3)\n",
    "        # print(kmer3,K)\n",
    "    elif K==4:\n",
    "        kmer4=jaccard_similarity(kmers1, kmers2)\n",
    "        CC.append(kmer4)\n",
    "        # print(kmer4,K)\n",
    "    elif K==5:\n",
    "        kmer5=jaccard_similarity(kmers1, kmers2)\n",
    "        CC.append(kmer5)\n",
    "        # print(kmer5,K)\n",
    "    elif K==6:\n",
    "        kmer6=jaccard_similarity(kmers1, kmers2)\n",
    "        CC.append(kmer6)\n",
    "        # print(kmer6,K)\n",
    "    elif K==7:\n",
    "        kmer7=jaccard_similarity(kmers1, kmers2)\n",
    "        CC.append(kmer7)\n",
    "        # print(kmer7,K)\n",
    "    elif K==8:\n",
    "        kmer8=jaccard_similarity(kmers1, kmers2)\n",
    "        CC.append(kmer8)        \n",
    "        # print(kmer8,K)\n",
    "    elif K==9:\n",
    "        kmer9=jaccard_similarity(kmers1, kmers2)\n",
    "        CC.append(kmer9)        \n",
    "        # print(kmer9,K)\n",
    "CC\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print([str(GG)])\n",
    "# df.to_csv(r'C:\\Users\\vghuser\\Desktop\\R\\all_c\\111111111111.csv',index=False)\n",
    "\n",
    "\n",
    "# c=bigram_sequence([str(GG)])\n",
    "# d=bigram_sequence([str(G1)])\n",
    "# print(c)\n",
    "# print(d)\n",
    "# def dice(c, d):\n",
    "#     c=set(c)\n",
    "#     d=set(d)\n",
    "#     # print(c)\n",
    "#     # print(d)\n",
    "#     return (2*len(c.intersection(d))) / (len(c) + len(d))\n",
    "# Dice=dice(c, d)\n",
    "# print(Dice)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ee77c-c523-4d62-8fb0-95708eeaf4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=bigram_sequence(rank_1_list)\n",
    "d=bigram_sequence(rank_2_list)\n",
    "print(c)\n",
    "print(d)\n",
    "\n",
    "def dice(c, d):\n",
    "    c=set(c)\n",
    "    d=set(d)\n",
    "    # print(c)\n",
    "    # print(d)\n",
    "    return (2*len(c.intersection(d))) / (len(c) + len(d))\n",
    "Dice=dice(c, d)\n",
    "print(Dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1b775636-85a1-4e9a-a10c-0c3f2bcbe6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\vghuser\\Desktop\\6\\1234.csv')\n",
    "CK=[]\n",
    "BK=[]\n",
    "DK=[]\n",
    "ll=[]\n",
    "ss=[]\n",
    "tt=[]\n",
    "for i in range(df.shape[0]):\n",
    "    # print(i)\n",
    "    BB=re.findall(r'\\d+',df['t_rank'][i])\n",
    "    CC=re.findall(r\"\\d+\",df['x12_rank'][i])\n",
    "    DD=re.findall(r'\\d+',df['x34_rank'][i])\n",
    "    \n",
    "    BK.append(BB)\n",
    "    CK.append(CC)\n",
    "    DK.append(DD) \n",
    "    \n",
    "df['t_rlist']=BK\n",
    "df['x12_rlist']=CK\n",
    "df['x34_rlist']=DK\n",
    "for t in df['t_rlist']:\n",
    "    # apa=int(i)\n",
    "    # print(apa)\n",
    "    results = list(map(int, t))\n",
    "    ll.append(results)\n",
    "for s in df['x12_rlist']:\n",
    "    # apa=int(i)\n",
    "    # print(apa)\n",
    "    results = list(map(int, s))\n",
    "    ss.append(results)\n",
    "    \n",
    "for s in df['x34_rlist']:\n",
    "    # apa=int(i)\n",
    "    # print(apa)\n",
    "    results = list(map(int, s))\n",
    "    tt.append(results)\n",
    "\n",
    "df['AAA']=ll\n",
    "df['BBB']=ss\n",
    "df['CCC']=tt\n",
    "# GG=tuple(ss[0])\n",
    "# G1=tuple(ss[1])\n",
    "\n",
    "# print(GG,G1)\n",
    "\n",
    "# df.to_csv(r'C:\\Users\\vghuser\\Desktop\\6\\777777.csv',index=False)\n",
    "\n",
    "\n",
    "# c=bigram_sequence([str(GG)])\n",
    "# d=bigram_sequence([str(G1)])\n",
    "# print(c)\n",
    "# print(d)\n",
    "# A=(1, 3, 2, 5, 7, 9, 4, 8, 10, 6, 12, 11)\n",
    "# B=(1, 7, 2, 4, 3, 9, 5, 8, 10, 12, 11, 6)\n",
    "# c=bigram_sequence(A)\n",
    "# d=bigram_sequence(B)\n",
    "# def dice(c, d):\n",
    "#     c=set(c)\n",
    "#     d=set(d)\n",
    "#     # print(c)\n",
    "#     # print(d)\n",
    "#     return (2*len(c.intersection(d))) / (len(c) + len(d))\n",
    "# Dice=dice(c, d)\n",
    "# print(Dice)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa",
   "language": "python",
   "name": "a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
